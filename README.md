# Building a Deep Neural Network Step by Step 

This assignment involves implementing a deep L-layer neural network step-by-step using only NumPy. The network is capable of classifying a non-linear dataset by combining forward propagation, backward propagation, cost computation, and parameter updates in a modular, extensible structure.  
This repository contains my implementation of the Week 4 programming assignment from the **Deep Learning Specialization** (Course 1: Neural Networks and Deep Learning) by **Andrew Ng**.

##  Description

In this assignment, I built a flexible L-layer deep neural network model that generalizes well to complex datasets. The implementation focuses on modular code — separating initialization, forward and backward propagation, cost calculation, and optimization — which helps in scaling to deeper architectures.

### Key Concepts Covered:
- Layer-wise parameter initialization
- Linear and activation forward steps
- Cost computation using cross-entropy loss
- Linear and activation backward steps
- Updating parameters with gradient descent
- Modular coding practices for deep learning

##  Technologies Used

- Python 3
- NumPy
- Matplotlib (for visualization)

##  Files

- `deep_neural_network.ipynb`: The main notebook where the deep model is implemented
- `testCases_v4a.py`: Test cases for verifying your functions
- `dnn_utils_v2.py`: Utility functions provided for activation and gradient calculations
- `datasets/`: Contains the non-linear dataset used for classification

> ⚠️ This repository includes only my own code and does not include any proprietary or auto-graded Coursera materials.

##  Course

Part of:
> [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)  
> Instructor: **Andrew Ng**

##  License

This repository is for educational and portfolio purposes only. Do not use it for submitting assignments directly to Coursera.

---

 If you're working on deep learning too, feel free to fork or star this repo!
